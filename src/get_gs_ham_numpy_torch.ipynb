{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-Jc23ehFFAE",
        "outputId": "d9be92d7-27f5-4d48-ac15-9e93d5df1d86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTR2wvLhyVPk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.sparse.linalg import eigsh\n",
        "from scipy import sparse\n",
        "from numpy import genfromtxt\n",
        "\n",
        "# initialize variables\n",
        "N = 10 # number of sites\n",
        "half_filling = True\n",
        "\n",
        "if half_filling == True:\n",
        "\n",
        "    N_e = N # total number of electrons\n",
        "    S_z = 0\n",
        "W = 2*N # each sites can have 2 electrons\n",
        "# Q is the dimension\n",
        "Q = pow(4, N)\n",
        "\n",
        "# decimal number to binary array function\n",
        "def D2B(num):\n",
        "    string = f'{num:1b}'\n",
        "    result = np.zeros(W-len(string), int)\n",
        "\n",
        "    for ele in string:\n",
        "        result = np.append(result, int(ele))\n",
        "\n",
        "    return result #nd array\n",
        "\n",
        "\n",
        "# binary array to decimal function\n",
        "def B2D(array):\n",
        "    res = 0\n",
        "    for ele in array:\n",
        "        res = (res << 1) | ele\n",
        "    return res[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5gJ-2_Xvywe"
      },
      "outputs": [],
      "source": [
        "half_N = N // 2  # Number of columns\n",
        "\n",
        "# Create a list of tuples representing the grid labels\n",
        "labels = [(row, col) for row in range(1, 3) for col in range(1, half_N + 1)]\n",
        "\n",
        "# Create a dictionary to map each label to a unique number starting from 0\n",
        "label_to_number = {label: index for index, label in enumerate(labels)}\n",
        "\n",
        "# Reverse the dictionary: keys become values and values become keys\n",
        "number_to_label = {v: k for k, v in label_to_number.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwdzqX3z2sRW",
        "outputId": "b4e5b680-172b-4eeb-e242-18e7d9847542"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: (1, 1),\n",
              " 1: (1, 2),\n",
              " 2: (1, 3),\n",
              " 3: (1, 4),\n",
              " 4: (1, 5),\n",
              " 5: (2, 1),\n",
              " 6: (2, 2),\n",
              " 7: (2, 3),\n",
              " 8: (2, 4),\n",
              " 9: (2, 5)}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "number_to_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewIKaRZHHNrK"
      },
      "outputs": [],
      "source": [
        "def are_nearest_neighbors(p1, p2):\n",
        "    \"\"\"\n",
        "    Check if two tuples representing grid coordinates are nearest neighbors.\n",
        "\n",
        "    Parameters:\n",
        "    p1 (tuple): The first coordinate (i, j).\n",
        "    p2 (tuple): The second coordinate (m, l).\n",
        "\n",
        "    Returns:\n",
        "    str: \"Yes\" if p1 and p2 are nearest neighbors, \"No\" otherwise.\n",
        "    \"\"\"\n",
        "    (i, j) = p1\n",
        "    (m, l) = p2\n",
        "\n",
        "    # Check if p1 and p2 are nearest neighbors\n",
        "    row_diff = abs(i - m)\n",
        "    col_diff = abs(j - l)\n",
        "\n",
        "    # Nearest neighbors if exactly one of the differences is 1 and the other is 0\n",
        "    if (row_diff == 1 and col_diff == 0) or (row_diff == 0 and col_diff == 1):\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeYilNlI2EvE",
        "outputId": "da627567-43bd-4637-a720-95567f320ba6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0., -1.,  0.,  0., -1., -1.,  0.,  0.,  0.,  0.],\n",
              "       [-1.,  0., -1.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
              "       [ 0., -1.,  0., -1.,  0.,  0.,  0., -1.,  0.,  0.],\n",
              "       [ 0.,  0., -1.,  0., -1.,  0.,  0.,  0., -1.,  0.],\n",
              "       [-1.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0., -1.],\n",
              "       [-1.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0., -1.],\n",
              "       [ 0., -1.,  0.,  0.,  0., -1.,  0., -1.,  0.,  0.],\n",
              "       [ 0.,  0., -1.,  0.,  0.,  0., -1.,  0., -1.,  0.],\n",
              "       [ 0.,  0.,  0., -1.,  0.,  0.,  0., -1.,  0., -1.],\n",
              "       [ 0.,  0.,  0.,  0., -1., -1.,  0.,  0., -1.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Initialize t_matrix\n",
        "t_matrix = np.zeros((N, N), dtype='float64')\n",
        "\n",
        "# Hopping value\n",
        "t_value = -1  # Nearest-neighbor (NN) hopping\n",
        "\n",
        "# Define periodic boundary condition (PBC) along rows\n",
        "PBC_condition = True\n",
        "\n",
        "for i in range(N):\n",
        "    if PBC_condition == True:\n",
        "        t_matrix[0][N//2-1] = t_value # the first row start and end value\n",
        "        t_matrix[N//2][N-1] = t_value # the second row start and end value this is enough it is always 2x N_x here\n",
        "    for j in range(N):\n",
        "        # now check if NN\n",
        "        if j >i:\n",
        "            if are_nearest_neighbors(number_to_label[i], number_to_label[j]):\n",
        "                t_matrix[i][j] = t_value\n",
        "\n",
        "# add another half back\n",
        "t_matrix = np.transpose(t_matrix) + t_matrix\n",
        "t_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daahURE-yapW"
      },
      "outputs": [],
      "source": [
        "# load  data\n",
        "file_path = f'/content/drive/My Drive/Hubbard_2024/2d/old_index_list={N}.txt'\n",
        "old_index_list = np.loadtxt(file_path, dtype=int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PujaeQpdeNbi",
        "outputId": "3890cfc8-63a3-4ff7-f920-e5e8d9f83338"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "184756\n"
          ]
        }
      ],
      "source": [
        "# N_e list getting a list with correct numberr of electrcons without sz limitation\n",
        "\n",
        "# create dict for new index in N_e sector\n",
        "\n",
        "NE_list=[]\n",
        "for i in range(Q):\n",
        "    state = D2B(i)\n",
        "    up_total=0\n",
        "    down_total=0\n",
        "    state_4_U = state.reshape((N, 2))\n",
        "    for j in range(N):\n",
        "        up_total = up_total + state_4_U[j][0]\n",
        "        down_total = down_total + state_4_U[j][1]\n",
        "    if (np.sum(state) == N_e):\n",
        "        NE_list.append(i)\n",
        "\n",
        "NE_dimension  = len(NE_list)\n",
        "print(NE_dimension)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMU_JiflykzH"
      },
      "outputs": [],
      "source": [
        "# The U part does not need matrix to do calculation it just attach a phase to the state vector later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhNYOGxJ31q1"
      },
      "outputs": [],
      "source": [
        "unit_U_matrix_row_list=[] # diagonal matrix anyways hence row is col as well, dimension is len( old_index_list )\n",
        "double_occ_site_index_list=[]\n",
        "for index, value in enumerate(old_index_list):\n",
        "\n",
        "    state = D2B(value)\n",
        "    # U part\n",
        "    # reshape it so that each array for one electron\n",
        "    state_4_U = state.reshape((N, 2))\n",
        "    # loop each array to see if how many double occuplied\n",
        "    number_of_double_occ_list = []\n",
        "    for j in range(N):\n",
        "        one_electron_array = state_4_U[j]\n",
        "        one_electron_array_sum = np.sum(one_electron_array)\n",
        "        if one_electron_array_sum ==2:\n",
        "            number_of_double_occ_list.append(j)\n",
        "    if len(number_of_double_occ_list)!=0:\n",
        "        double_occ_site_index_list.append(number_of_double_occ_list)\n",
        "        unit_U_matrix_row_list.append(index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwaU4MBu32kP"
      },
      "outputs": [],
      "source": [
        "# explain : unit_U_matrix_row_list is the list that gives the index of elements in old_index_list\n",
        "# that does not have double occ\n",
        "# For example, in N=4, it does not have 11 or 14,\n",
        "# bc D2B(old_index_list[11]) gives [0, 1, 0, 1, 1, 0, 1, 0]\n",
        "# D2B(old_index_list[14]) gives  [0, 1, 1, 0, 1, 0, 0, 1]\n",
        "# double_occ_site_index_list is the site index for that state, which site has double occ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jg-xPkS84IHf"
      },
      "outputs": [],
      "source": [
        "def get_sprase_U_matrix(input_array): #input array is the U value for each site\n",
        "    row = unit_U_matrix_row_list\n",
        "    col = unit_U_matrix_row_list\n",
        "\n",
        "    # get U value, number of double occ times the corresponding U value\n",
        "    data = np.zeros(len(row))\n",
        "    for index in range(len(double_occ_site_index_list)):\n",
        "        value = double_occ_site_index_list[index]\n",
        "        total_U_for_one_state = 0\n",
        "        for site_index in value:\n",
        "            total_U_for_one_state = total_U_for_one_state + input_array[site_index]\n",
        "        data[index] = total_U_for_one_state\n",
        "\n",
        "    sprase_U_matrix = sparse.coo_matrix((data, (row, col)), shape=(len(old_index_list), len(old_index_list) ) ) # len of old is full dimension\n",
        "    # row col is the ones with non zero U value\n",
        "\n",
        "    return sprase_U_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCfhUz6e5PGb"
      },
      "outputs": [],
      "source": [
        "# this cell is getting all the possible hopping and put it into a product state basis matrix and to fill in the hopping strength later\n",
        "# can be limited to t matrix if N is too big to get all the possible hopping case\n",
        "new_index_list=np.arange(0,len(old_index_list))\n",
        "index_dict = dict(zip(old_index_list, new_index_list))\n",
        "\n",
        "unit_hop_matrix_row_list=[]\n",
        "unit_hop_matrix_col_list=[]\n",
        "unit_hop_matrix_data_list=[]\n",
        "data_site_row_list =[]\n",
        "data_site_col_list =[]\n",
        "\n",
        "# start looping each state and see what other states it couple to\n",
        "for index, value in enumerate(old_index_list):\n",
        "\n",
        "    state = D2B(value)\n",
        "    # reshape it so that each array for one electron\n",
        "    state_4_U = state.reshape((N, 2))\n",
        "\n",
        "    # t part\n",
        "\n",
        "    # where it starts to hop\n",
        "    for j in range(N):\n",
        "        # loop where it hops to\n",
        "        for k in range(N):\n",
        "\n",
        "            # up spin part  that is why [0]\n",
        "            if state_4_U[j][0]==1 and state_4_U[k][0]==0:\n",
        "                number_pass = 0\n",
        "                hop_state = np.copy(state_4_U) # a copy of the state so that it won't change the original one\n",
        "                state_to_count = np.copy(state)\n",
        "                start_position = 2*j\n",
        "                # count how many from the edge to start position\n",
        "                number_pass = number_pass + np.sum(state_to_count[:start_position])\n",
        "                # remove that one\n",
        "                state_to_count[start_position] = 0\n",
        "                # count how many from the edge to end position\n",
        "                end_position = 2*k\n",
        "                number_pass = number_pass + np.sum(state_to_count[:end_position])\n",
        "                hop_state[j][0] =0\n",
        "                hop_state[k][0] =1\n",
        "                # new number\n",
        "                hop_state = hop_state.reshape((2*N, 1))\n",
        "                new_num = B2D(hop_state)\n",
        "                # for hopping matrix\n",
        "\n",
        "                unit_hop_matrix_row_list.append(index)\n",
        "                unit_hop_matrix_col_list.append(index_dict[new_num])\n",
        "                unit_hop_matrix_data_list.append(pow(-1,number_pass))\n",
        "                data_site_row_list.append(j)\n",
        "                data_site_col_list.append(k)\n",
        "\n",
        "\n",
        "            # down spin part\n",
        "            if state_4_U[j][1]==1 and state_4_U[k][1]==0:\n",
        "                number_pass = 0\n",
        "                hop_state = np.copy(state_4_U) # a copy of the real state so that it won't change the original one\n",
        "                state_to_count = np.copy(state)\n",
        "                start_position = 2*j+1\n",
        "                # count how many from the edge to start position\n",
        "                number_pass = number_pass + np.sum(state_to_count[:start_position])\n",
        "                # remove that one\n",
        "                state_to_count[start_position] = 0\n",
        "                # count how many from the edge to end position\n",
        "                end_position = 2*k+1\n",
        "                number_pass = number_pass + np.sum(state_to_count[:end_position])\n",
        "                hop_state[j][1] =0\n",
        "                hop_state[k][1] =1\n",
        "                # new number\n",
        "                hop_state = hop_state.reshape((2*N, 1))\n",
        "                new_num = B2D(hop_state)\n",
        "                # for hopping matrix\n",
        "                unit_hop_matrix_row_list.append(index)\n",
        "                unit_hop_matrix_col_list.append(index_dict[new_num])\n",
        "                unit_hop_matrix_data_list.append(pow(-1,number_pass))\n",
        "                data_site_row_list.append(j)\n",
        "                data_site_col_list.append(k)\n",
        "\n",
        "unit_hop_matrix_row_list= np.array (unit_hop_matrix_row_list)\n",
        "unit_hop_matrix_col_list= np.array (unit_hop_matrix_col_list)\n",
        "unit_hop_matrix_data_list= np.array (unit_hop_matrix_data_list)\n",
        "data_site_row_list = np.array(data_site_row_list)\n",
        "data_site_col_list = np.array(data_site_col_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5IweUN27xrg"
      },
      "outputs": [],
      "source": [
        "# get sprase H_hop\n",
        "def get_sprase_hop_matrix(t_matrix_input): #input array is the U value for each site\n",
        "\n",
        "\n",
        "    hop_matrix_data_list = []\n",
        "\n",
        "    for index, value in enumerate(unit_hop_matrix_data_list):\n",
        "\n",
        "        site_index_row = data_site_row_list[index]\n",
        "        site_index_col = data_site_col_list[index]\n",
        "\n",
        "        new_value = value * t_matrix_input[site_index_row][site_index_col] # value is either 1 or -1 and times the strength at the corresponding site\n",
        "\n",
        "        hop_matrix_data_list.append(new_value)\n",
        "    hop_matrix_data_list =np.array(hop_matrix_data_list)\n",
        "    # hop_matrix_data_list is the data later is the dimension for where to fill and then is the full dimension\n",
        "    sprase_hop_matrix_1 = sparse.coo_matrix( ( hop_matrix_data_list, (unit_hop_matrix_row_list, unit_hop_matrix_col_list) )\n",
        "                                          , shape=(len(old_index_list), len(old_index_list) ) ) # len of old is full dimension\n",
        "\n",
        "    return sprase_hop_matrix_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_UEhlu2q4Y-"
      },
      "outputs": [],
      "source": [
        "# def fidelity(state1, state2):\n",
        "#     return np.abs(np.vdot(state1, state2))**2\n",
        "\n",
        "# # List to store ground states\n",
        "# ground_states = []\n",
        "\n",
        "# # Generate ground states for different U values\n",
        "# U_value_list = np.array([0,2,4,6,8,10,12,14,16,18,20])\n",
        "# # U_value_list = np.array([0,4,8,12])\n",
        "# # U_value_list = np.array([0,8])\n",
        "# for U_value in U_value_list:\n",
        "#     h_sparse = get_sprase_hop_matrix(t_matrix) + get_sprase_U_matrix(np.ones(N)*U_value)\n",
        "#     result = sparse.linalg.eigsh(h_sparse, k=1, which='SA')\n",
        "#     true_gs = result[1][:, 0]  # Extract the ground state (eigenvector)\n",
        "#     ground_states.append(true_gs)\n",
        "\n",
        "# # Calculate fidelity between consecutive ground states\n",
        "# fidelities = []\n",
        "# for i in range(len(ground_states) - 1):\n",
        "#     fid = fidelity(ground_states[i], ground_states[i+1])\n",
        "#     fidelities.append(fid)\n",
        "#     print(f\"Fidelity between U={U_value_list[i]} and U={U_value_list[i+1]}: {fid}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IyOOgcrQmZQ"
      },
      "outputs": [],
      "source": [
        "def s2_op(input_state):\n",
        "    #calculating S+S- only, c.c. gives S-S+. Also, phi S+S- psi can be simplified to just S- onto psi to know the scaling factor,and Sz is easy to get,assuming 0 or 1\n",
        "    # lowering part\n",
        "    new_state = np.zeros(len(NE_list))\n",
        "    for index,value in enumerate(old_index_list): # loop over every computational basis\n",
        "        state = D2B(value)\n",
        "        # reshape it so that each array for one electron\n",
        "        state_4_U = state.reshape((N, 2))\n",
        "        for j in range(N):\n",
        "            hop_state = np.copy(state_4_U) # a copy of the real state so that it won't change the original one\n",
        "            # up spin part\n",
        "            if (state_4_U[j][0]==1) and (state_4_U[j][1]==0):\n",
        "                # same site all the time hence it's sqaure of the either -1 or 1 but both give 1\n",
        "                hop_state[j][0] = 0\n",
        "                hop_state[j][1] = 1\n",
        "                # new number\n",
        "                hop_state = hop_state.reshape((2*N, 1))\n",
        "                new_num = B2D(hop_state)\n",
        "                #print(new_num)\n",
        "                # Correct usage of index method\n",
        "                try:\n",
        "                    new_index = NE_list.index(new_num)\n",
        "                    new_state[new_index] +=  input_state[index]  # Update new_state using the scaling factor\n",
        "                except ValueError:\n",
        "                    # Handle the case if new_num is not found in NE_list\n",
        "                    print(f\"Value {new_num} not found in NE_list.\")\n",
        "    value1 = np.round( pow(np.linalg.norm(new_state),2),7)\n",
        "    # raising part\n",
        "    new_state = np.zeros(len(NE_list))\n",
        "    for index,value in enumerate(old_index_list): # loop over every computational basis\n",
        "        state = D2B(value)\n",
        "        # reshape it so that each array for one electron\n",
        "        state_4_U = state.reshape((N, 2))\n",
        "        for j in range(N):\n",
        "            hop_state = np.copy(state_4_U) # a copy of the real state so that it won't change the original one\n",
        "            # up spin part\n",
        "            if (state_4_U[j][0]==0) and (state_4_U[j][1]==1):\n",
        "                # same site all the time hence it's sqaure of the either -1 or 1 but both give 1\n",
        "                hop_state[j][0] = 1\n",
        "                hop_state[j][1] = 0\n",
        "                # new number\n",
        "                hop_state = hop_state.reshape((2*N, 1))\n",
        "                new_num = B2D(hop_state)\n",
        "                #print(new_num)\n",
        "                # Correct usage of index method\n",
        "                try:\n",
        "                    new_index = NE_list.index(new_num)\n",
        "                    new_state[new_index] +=  input_state[index]  # Update new_state using the scaling factor\n",
        "                except ValueError:\n",
        "                    # Handle the case if new_num is not found in NE_list\n",
        "                    print(f\"Value {new_num} not found in NE_list.\")\n",
        "    value2 = np.round( pow(np.linalg.norm(new_state),2),7)\n",
        "\n",
        "    return (value1+value2)/2   # this is S(S+1) value without Sz^2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read def spin matrix\n",
        "# Define the path in Google Drive\n",
        "file_path = f'/content/drive/My Drive/Hubbard_2024/2d/definite_spin_matrix_N={N}.npz'\n",
        "\n",
        "# Read the sparse matrix\n",
        "spin_matrix = sparse.load_npz(file_path)\n",
        "\n",
        "def quantum_expectation(sparse_matrix, phi):\n",
        "    \"\"\"\n",
        "    Calculates the quantum mechanical expectation value of the form phi^H * matrix * phi.\n",
        "\n",
        "    Args:\n",
        "      sparse_matrix: A sparse matrix (e.g., scipy.sparse.csr_matrix).\n",
        "      phi: A NumPy array representing the state vector.\n",
        "\n",
        "    Returns:\n",
        "      The scalar expectation value of the form phi^H * matrix * phi, rounded to 7 decimal places.\n",
        "    \"\"\"\n",
        "    # Step 1: Take the conjugate transpose of phi\n",
        "    phi_conj = np.conjugate(phi)\n",
        "\n",
        "    # Step 2: Multiply the sparse matrix with phi to get an intermediate result\n",
        "    intermediate_result = sparse_matrix.dot(phi)\n",
        "\n",
        "    # Step 3: Compute the final dot product (phi_conj * intermediate_result)\n",
        "    result = phi_conj @ intermediate_result  # Using @ for dot product for better readability\n",
        "\n",
        "    # Step 4: Return the result rounded to 7 decimal places\n",
        "    return np.round(result, 7)\n"
      ],
      "metadata": {
        "id": "zh6JCfijMcDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBv5kNwquaC5"
      },
      "outputs": [],
      "source": [
        "U_value_list = np.array([1,2,4,6,8,16])\n",
        "summary_data = []\n",
        "for U_value in U_value_list:\n",
        "    number_of_excited_state = 10\n",
        "    h_sprase = get_sprase_hop_matrix(t_matrix) + get_sprase_U_matrix(np.ones(N)*U_value)\n",
        "    sparse.save_npz(f'/content/drive/My Drive/Hubbard_2024/2d/es/torch_h_sparse_N_{N}_U_{U_value}.npz', h_sprase.tocoo())\n",
        "    result = sparse.linalg.eigsh(h_sprase, k=10, which='SA')\n",
        "    true_gs = result[1].T[0]\n",
        "\n",
        "    # also serve as a check\n",
        "    S_value_gs = quantum_expectation(spin_matrix,true_gs)\n",
        "    # or use general method\n",
        "    #S_value_gs = s2_op(true_gs)\n",
        "    print('S_value_gs is',S_value_gs)\n",
        "    # now find the same S first couple excited state\n",
        "\n",
        "    for state_index in range(1,number_of_excited_state):\n",
        "        exctied_state = result[1].T[state_index]\n",
        "\n",
        "        # get S value\n",
        "        S_value = quantum_expectation(spin_matrix,exctied_state)\n",
        "        #S_value = s2_op(exctied_state)\n",
        "        print(S_value)\n",
        "        if S_value == S_value_gs:\n",
        "            first_excited_state = exctied_state # bc we are looking for the lowest enregy one, automatically handled by the ranking of the vector already\n",
        "            print('state_index is ', state_index,'S_value is ',S_value )\n",
        "            break\n",
        "\n",
        "    # save result\n",
        "    np.savetxt(f'/content/drive/My Drive/Hubbard_2024/2d/es/true_gs_energy_N_{N}_U_{U_value}.csv', [result[0][0]], delimiter=',')\n",
        "    np.savetxt(f'/content/drive/My Drive/Hubbard_2024/2d/es/first_couple_excited_energy_N_{N}_U_{U_value}.csv', [result[0][state_index]], delimiter=',')\n",
        "    np.savetxt(f'/content/drive/My Drive/Hubbard_2024/2d/es/true_gs_N_{N}_U_{U_value}.csv', true_gs, delimiter=',')\n",
        "    np.savetxt(f'/content/drive/My Drive/Hubbard_2024/2d/es/first_couple_excited_state_N_{N}_U_{U_value}_Ne.csv', first_excited_state, delimiter=',')\n",
        "    np.savetxt(f'/content/drive/My Drive/Hubbard_2024/2d/es/first_excited_energy_N_{N}_U_{U_value}.csv', [result[0][1]], delimiter=',')\n",
        "    np.savetxt(f'/content/drive/My Drive/Hubbard_2024/2d/es/first_excited_state_N_{N}_U_{U_value}.csv', first_excited_state, delimiter=',')\n",
        "\n",
        "    # Add to summary data\n",
        "    summary_data.append({\n",
        "        \"U_value\": U_value,\n",
        "        \"gs_energy\": result[0][0],\n",
        "        \"first_couple_excited_energy\": result[0][state_index],\n",
        "        \"first_excited_energy\": result[0][1]\n",
        "    })\n",
        "\n",
        "# Print summary of energies at the end\n",
        "print(\"\\nSummary of energies for different U values:\")\n",
        "for data in summary_data:\n",
        "    print(f\"U = {data['U_value']}: GS Energy = {data['gs_energy']}, First Couple Excited Energy = {data['first_couple_excited_energy']}, First Excited Energy = {data['first_excited_energy']}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# N = 8\n",
        "# S_value_gs is -0.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# -0.0\n",
        "# state_index is  5 S_value is  -0.0\n",
        "# S_value_gs is -0.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 0.0\n",
        "# state_index is  5 S_value is  0.0\n",
        "# S_value_gs is -0.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 0.0\n",
        "# state_index is  5 S_value is  0.0\n",
        "# S_value_gs is 0.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 6.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# -0.0\n",
        "# state_index is  9 S_value is  -0.0\n",
        "# S_value_gs is -0.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 6.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# -0.0\n",
        "# state_index is  9 S_value is  -0.0\n",
        "# S_value_gs is 0.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 6.0\n",
        "# 0.0\n",
        "# state_index is  9 S_value is  0.0\n",
        "\n",
        "# Summary of energies for different U values:\n",
        "# U = 1: GS Energy = -10.118762934506028, First Couple Excited Energy = -8.145959053711838, First Excited Energy = -8.491884337534497\n",
        "# U = 2: GS Energy = -8.478303296869594, First Couple Excited Energy = -6.5857864444709655, First Excited Energy = -7.206741230016821\n",
        "# U = 4: GS Energy = -5.954236681057318, First Couple Excited Energy = -4.356277445472863, First Excited Energy = -5.256982547718461\n",
        "# U = 8: GS Energy = -3.4671734372139245, First Couple Excited Energy = -2.4370455114703824, First Excited Energy = -3.1753036376269583\n",
        "# U = 16: GS Energy = -1.8772690847081202, First Couple Excited Energy = -1.3136244826137233, First Excited Energy = -1.701812766199699"
      ],
      "metadata": {
        "id": "wPPYKHffsH0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2E0-h0E_YPr"
      },
      "outputs": [],
      "source": [
        "# S_value_gs is 2.0\n",
        "# 0.0\n",
        "# -0.0\n",
        "# 0.0\n",
        "# 2.0\n",
        "# state_index is  4 S_value is  2.0\n",
        "# S_value_gs is 2.0\n",
        "# 0.0\n",
        "# 0.0\n",
        "# 0.0\n",
        "# 2.0\n",
        "# state_index is  4 S_value is  2.0\n",
        "# S_value_gs is -0.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# -0.0\n",
        "# state_index is  4 S_value is  -0.0\n",
        "# S_value_gs is -0.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# -0.0\n",
        "# state_index is  4 S_value is  -0.0\n",
        "# S_value_gs is 0.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# -0.0\n",
        "# state_index is  4 S_value is  -0.0\n",
        "# S_value_gs is -0.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# 2.0\n",
        "# -0.0\n",
        "# state_index is  4 S_value is  -0.0\n",
        "\n",
        "# Summary of energies for different U values:\n",
        "# U = 1: GS Energy = -11.453171087300346, First Couple Excited Energy = -11.230390277938188, First Excited Energy = -11.3813361188669\n",
        "# U = 2: GS Energy = -9.508902323907462, First Couple Excited Energy = -9.325412309894787, First Excited Energy = -9.47281389008344\n",
        "# U = 4: GS Energy = -6.805335072522798, First Couple Excited Energy = -6.4635195428644066, First Excited Energy = -6.642914070897716\n",
        "# U = 8: GS Energy = -4.1546970562649035, First Couple Excited Energy = -3.6828367397433164, First Excited Energy = -3.887124616402076\n",
        "# U = 16: GS Energy = -2.2617602698499937, First Couple Excited Energy = -1.936516763551882, First Excited Energy = -2.0731243851171044"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bqeM895F_7GN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YK3ps-Kv2uwO"
      },
      "outputs": [],
      "source": [
        "# # check after multiplying definite spin\n",
        "\n",
        "# #Define the path in Google Drive\n",
        "# file_path = f'/content/drive/My Drive/Hubbard_2024/product_state/definite_spin_basis_N={N}.npz'\n",
        "# #Save the sparse matrix\n",
        "# definite_spin_basis= sparse.load_npz(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IP7lNF3n2_J2"
      },
      "outputs": [],
      "source": [
        "# def_spin_h_sprase = definite_spin_basis*h_sprase*definite_spin_basis.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-8isGpWh9sn"
      },
      "outputs": [],
      "source": [
        "# sparse.linalg.eigsh(h_sprase, k=174, which='SA')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-_5pVSYiCcg"
      },
      "outputs": [],
      "source": [
        "# sparse.linalg.eigsh(def_spin_h_sprase, k=10, which='SA')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDwQK8-QiGvM"
      },
      "outputs": [],
      "source": [
        "# definite spin h is much more dense than the original H , use original H instead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-rm5Fx3iqmE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}