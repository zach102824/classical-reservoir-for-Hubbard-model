{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-Jc23ehFFAE",
        "outputId": "3f9040f6-f975-48d0-a6ff-192ba0fd01cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTR2wvLhyVPk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "import torch\n",
        "from numpy import genfromtxt\n",
        "from matplotlib import pyplot as plt\n",
        "# initialize variables\n",
        "N = 10 # number of sites\n",
        "half_filling = True\n",
        "\n",
        "if half_filling == True:\n",
        "\n",
        "    N_e = N # total number of electrons\n",
        "    S_z = 0\n",
        "W = 2*N # each sites can have 2 electrons\n",
        "# Q is the dimension\n",
        "Q = pow(4, N)\n",
        "\n",
        "# decimal number to binary array function\n",
        "def D2B(num):\n",
        "    string = f'{num:1b}'\n",
        "    result = np.zeros(W-len(string), int)\n",
        "\n",
        "    for ele in string:\n",
        "        result = np.append(result, int(ele))\n",
        "\n",
        "    return result #nd array\n",
        "\n",
        "\n",
        "# binary array to decimal function\n",
        "def B2D(array):\n",
        "    res = 0\n",
        "    for ele in array:\n",
        "        res = (res << 1) | ele\n",
        "    return res[0]\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCh3_YZMo4_n"
      },
      "outputs": [],
      "source": [
        "def scipy_to_torch_sparse(scipy_coo_matrix):\n",
        "    \"\"\"\n",
        "    Convert a SciPy sparse COO matrix to a PyTorch sparse COO matrix.\n",
        "\n",
        "    Parameters:\n",
        "    scipy_coo_matrix (scipy.sparse.coo_matrix): The input SciPy sparse COO matrix.\n",
        "\n",
        "    Returns:\n",
        "    torch.sparse_coo_tensor: The converted PyTorch sparse COO tensor.\n",
        "    \"\"\"\n",
        "    if not isinstance(scipy_coo_matrix,scipy.sparse.coo_matrix):\n",
        "        raise TypeError(\"Input matrix must be a SciPy sparse COO matrix\")\n",
        "\n",
        "    # Extract row, column, and data\n",
        "    row = torch.tensor(scipy_coo_matrix.row, dtype=torch.long)\n",
        "    col = torch.tensor(scipy_coo_matrix.col, dtype=torch.long)\n",
        "    data = torch.tensor(scipy_coo_matrix.data)\n",
        "\n",
        "    # Create the indices tensor\n",
        "    indices = torch.stack([row, col], dim=0)\n",
        "\n",
        "    # Create the PyTorch sparse COO tensor\n",
        "    torch_sparse_tensor = torch.sparse_coo_tensor(indices, data, scipy_coo_matrix.shape, dtype=torch.complex128)\n",
        "\n",
        "    return torch_sparse_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjjvA4NMlBOW"
      },
      "outputs": [],
      "source": [
        "# load  data\n",
        "file_path = f'/content/drive/My Drive/Hubbard_2024/2d/old_index_list={N}.txt'\n",
        "old_index_list = np.loadtxt(file_path, dtype=int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMU_JiflykzH"
      },
      "outputs": [],
      "source": [
        "U_value = 2\n",
        "# Load the sparse matrix in pytorch COO format with complex 128 data\n",
        "h_sparse = scipy.sparse.load_npz(f'/content/drive/My Drive/Hubbard_2024/2d/es/torch_h_sparse_N_{N}_U_{U_value}.npz')\n",
        "h_sparse = scipy_to_torch_sparse(h_sparse)\n",
        "h_sparse = h_sparse.to(device)\n",
        "# Load the eigenvalues\n",
        "true_gs_energy = np.loadtxt(f'/content/drive/My Drive/Hubbard_2024/2d/es/true_gs_energy_N_{N}_U_{U_value}.csv', delimiter=',')\n",
        "\n",
        "# Load the eigenvectors\n",
        "true_gs = np.loadtxt(f'/content/drive/My Drive/Hubbard_2024/2d/es/true_gs_N_{N}_U_{U_value}.csv', delimiter=',')\n",
        "# move to gpu\n",
        "true_gs = torch.tensor(true_gs, dtype=torch.complex128).to(device)\n",
        "# definite spin matrix\n",
        "#def_spin_matrix = sparse.load_npz(f'/content/drive/My Drive/Hubbard_2024/2d/definite_spin_matrix_N={N}.npz')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJfJGKiFmpal",
        "outputId": "5e8d9dca-7a43-4840-c6a9-3087be7c3e91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-9.508902323907462\n"
          ]
        }
      ],
      "source": [
        "print(true_gs_energy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w37fRXz4GE5D"
      },
      "outputs": [],
      "source": [
        "def calculate_energy(input_matrix, psi): # input_matrix is sparse\n",
        "    psi_dagger = torch.conj(psi)  # Conjugate of the state vector\n",
        "\n",
        "    # Sparse matrix-vector multiplication\n",
        "    intermediate = torch.sparse.mm(input_matrix, psi.unsqueeze(1))  # shape (n, 1)\n",
        "\n",
        "    # Dot product to get the energy\n",
        "    energy = torch.dot(psi_dagger, intermediate.squeeze())  # shape (n,)\n",
        "\n",
        "    return energy.real"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTMVHh47DQgF",
        "outputId": "bf1303a6-2f7d-4ed7-bb4b-d6ec5bbbf5d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(-9.5089, device='cuda:0', dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "print(calculate_energy(h_sparse,true_gs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDpZqjj4_ckI"
      },
      "outputs": [],
      "source": [
        "# test code to check calculate eneryg is correct\n",
        "# print(calculate_energy(h_sparse,true_gs)-true_gs_energy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiLcoN0X80H3"
      },
      "outputs": [],
      "source": [
        "random_state = False\n",
        "state_to_evolve = torch.zeros(len(true_gs), dtype=torch.complex128)\n",
        "\n",
        "# Set up PyTorch random number generator\n",
        "torch.manual_seed(0)  # Set a fixed random seed for reproducibility\n",
        "\n",
        "# Initialize state_to_evolve based on random_state and N\n",
        "if random_state:\n",
        "    state_to_evolve_real = torch.rand(len(true_gs), dtype=torch.float64) * 2 - 1\n",
        "    state_to_evolve_imag = torch.rand(len(true_gs), dtype=torch.float64) * 2 - 1\n",
        "    state_to_evolve = state_to_evolve_real + 1j * state_to_evolve_imag\n",
        "else:\n",
        "    if N == 8:\n",
        "        state_to_evolve[4005] = 1\n",
        "    elif N == 4:\n",
        "        state_to_evolve[5] = 1\n",
        "    elif N == 6:\n",
        "        if U_value == 8:\n",
        "            state_to_evolve[64] = 1\n",
        "        else:\n",
        "            state_to_evolve[70] = 1\n",
        "            state_to_evolve[71] = 1\n",
        "    elif N == 10:\n",
        "        if U_value == 8:\n",
        "\n",
        "            state_to_evolve[51633] = 1\n",
        "        if U_value == 2:\n",
        "            state_to_evolve[11871] = 1\n",
        "            state_to_evolve[11872] = 1\n",
        "\n",
        "    elif N == 12:\n",
        "        state_to_evolve[691965] = 1 # or index 161810\n",
        "\n",
        "# Normalize the state vector\n",
        "state_to_evolve = state_to_evolve / torch.norm(state_to_evolve)\n",
        "\n",
        "# move to gpu\n",
        "state_to_evolve = state_to_evolve.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zc_HyDQOeLSI"
      },
      "outputs": [],
      "source": [
        "# # if start with U=0 ground state\n",
        "\n",
        "# # Load the eigenvectors\n",
        "# state_to_evolve = np.loadtxt(f'/content/drive/My Drive/Hubbard_2024/2d/true_gs_N_{N}_U_{0}.csv', delimiter=',')\n",
        "# # move to gpu\n",
        "# state_to_evolve = torch.tensor(state_to_evolve, dtype=torch.complex128).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ris2Xhh-tWu9"
      },
      "outputs": [],
      "source": [
        "def calculate_fidelity(psi, phi):\n",
        "    \"\"\"\n",
        "    Calculate the fidelity between two state vectors.\n",
        "\n",
        "    Parameters:\n",
        "    psi (torch.Tensor): The first state vector in PyTorch format, dtype=torch.complex128.\n",
        "    phi (torch.Tensor): The second state vector in PyTorch format, dtype=torch.complex128.\n",
        "\n",
        "    Returns:\n",
        "    float: The calculated fidelity.\n",
        "    \"\"\"\n",
        "    fidelity = torch.abs(torch.vdot(psi, phi))**2\n",
        "    return fidelity.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fR_m4Cqlqqp",
        "outputId": "feef2380-6ae4-466d-f6b9-d4bba19cde2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.135674130993585e-07"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "calculate_fidelity(state_to_evolve,true_gs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdwo9xMOyq9T",
        "outputId": "594c111b-1f58-4bd0-e218-bdbd38bffae0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.0000, device='cuda:0', dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "# # check the energy of the state to evolve\n",
        "print(calculate_energy(h_sparse,state_to_evolve))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3wIFKd3C7Aj"
      },
      "outputs": [],
      "source": [
        "# U part, read data\n",
        "file_path = f'/content/drive/My Drive/Hubbard_2024/2d/number_op_list_N={N}.txt'\n",
        "number_op_list = torch.tensor(np.loadtxt(file_path))\n",
        "# move to gpu\n",
        "number_op_list = number_op_list.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmU7WadEJ9mN"
      },
      "outputs": [],
      "source": [
        "def UCC_U_part_torch(input_state, para_index, input_theta):\n",
        "    \"\"\"\n",
        "    Apply the UCC U part operation on the input state.\n",
        "\n",
        "    Parameters:\n",
        "    input_state (torch.Tensor): The input state tensor in PyTorch format, dtype=torch.complex128.\n",
        "    para_index (int): The index to select the corresponding number operator from number_op_list.\n",
        "    input_theta (float): The input theta parameter for the phase factor.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: The output state after applying the phase factors.\n",
        "    \"\"\"\n",
        "    occ_list = number_op_list[para_index]\n",
        "\n",
        "    # Compute the phase factors\n",
        "    phase_factor_list = torch.exp(1j * input_theta * occ_list)\n",
        "\n",
        "    # Apply the phase factors to the input state\n",
        "    output_state = phase_factor_list * input_state\n",
        "\n",
        "    return output_state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCzFXjis1Jx4"
      },
      "outputs": [],
      "source": [
        "# UCC_U_part_torch(state_to_evolve,2,torch.tensor([0.3],dtype=torch.float64).to(device ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9hAwE61KGqZ"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "# Specify the file path to save the dictionary\n",
        "file_path = f'/content/drive/My Drive/Hubbard_2024/2d/torch_hopping_cose_dict_N={N}.pkl'\n",
        "\n",
        "# Load the dictionary from the file\n",
        "hopping_cose_dict = pickle.load(open(file_path, 'rb'))\n",
        "\n",
        "# Convert numpy arrays to torch tensors\n",
        "hopping_cose_dict = {key: torch.tensor(value, device=device) for key, value in hopping_cose_dict.items()}\n",
        "\n",
        "file_path = f'/content/drive/My Drive/Hubbard_2024/2d/torch_sparse_matrices_dict_N={N}.pkl'\n",
        "\n",
        "# Load the dictionary from the file\n",
        "sparse_matrices_dict = pickle.load(open(file_path, 'rb'))\n",
        "\n",
        "# Convert SciPy sparse COO matrices to PyTorch sparse COO tensors\n",
        "sparse_matrices_dict = {key: scipy_to_torch_sparse(value) for key, value in sparse_matrices_dict.items()}\n",
        "# Move PyTorch sparse COO tensors to GPU\n",
        "sparse_matrices_dict = {key: value.to(device) for key, value in sparse_matrices_dict.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-7gIpfJKERQ"
      },
      "outputs": [],
      "source": [
        "def UCC_t_part_torch(input_state, hopping_pair_site, ri_sign, input_theta):\n",
        "    \"\"\"\n",
        "    Apply the UCC t part operation on the input state.\n",
        "\n",
        "    Parameters:\n",
        "    input_state (torch.Tensor): The input state tensor in PyTorch format, dtype=torch.complex128.\n",
        "    hopping_pair_site (tuple): The hopping pair site indices.\n",
        "    ri_sign (int): The sign indicating the type of sine part calculation.\n",
        "    input_theta (float): The input theta parameter for the phase factor.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: The output state after applying the phase factors.\n",
        "    \"\"\"\n",
        "    # Loop over spins since both need to be applied\n",
        "    for spin in [1, -1]:\n",
        "        # Define the hopping pair including the spin\n",
        "        hopping_pair = hopping_pair_site + (spin,)\n",
        "\n",
        "        # Cosine part\n",
        "        cos_list = torch.ones(len(true_gs), dtype=torch.complex128).to(device)\n",
        "        cos_list_index = hopping_cose_dict[hopping_pair]\n",
        "        cos_list[cos_list_index] = torch.cos(input_theta).to(torch.complex128)\n",
        "        part1 = cos_list * input_state\n",
        "\n",
        "        # Sine part\n",
        "        input_state = input_state.view(-1, 1)\n",
        "        if ri_sign == 1:\n",
        "            hop_matrix = sparse_matrices_dict[hopping_pair] - sparse_matrices_dict[hopping_pair].transpose(0, 1)\n",
        "            part2 = torch.sparse.mm(hop_matrix, input_state).view(-1)\n",
        "            final_state = part1 + torch.sin(input_theta).to(torch.complex128) * part2\n",
        "        else:\n",
        "            hop_matrix = sparse_matrices_dict[hopping_pair] + sparse_matrices_dict[hopping_pair].transpose(0, 1)\n",
        "            part2 =torch.sparse.mm(hop_matrix, input_state).view(-1)\n",
        "            final_state = part1 + 1j * torch.sin(input_theta).to(torch.complex128) * part2\n",
        "\n",
        "        # Update the state for spin down, i.e., -1\n",
        "        input_state = final_state\n",
        "\n",
        "    return final_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geJHPZ_Gsj7V"
      },
      "outputs": [],
      "source": [
        "## numerical check using actual matrix exponetial, real part\n",
        "\n",
        "# SU2 method\n",
        "# UCC_t_part_torch(state_to_evolve, (0,3),-1,torch.tensor([0.3],dtype=torch.float64).to(device ))\n",
        "# # numerical\n",
        "# b = sparse_matrices_dict[(0,3,1)]+ sparse_matrices_dict[(0,3,1)].T+ sparse_matrices_dict[(0,3,-1)]+ sparse_matrices_dict[(0,3,-1)].T\n",
        "# b = b.to_dense()\n",
        "# torch.matrix_exp(b)\n",
        "# torch.matmul(torch.matrix_exp(b),state_to_evolve) - UCC_t_part_torch(state_to_evolve, (0,1),-1,torch.tensor([0.3],dtype=torch.complex128).to(device ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sgdtaRxentX",
        "outputId": "5a987d47-5a16-40bf-a9d7-7c20f268a27d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final para_value_list with commuting groups and U terms ordered:\n",
            "437 [(0, 1, -1, 0), (2, 3, -1, 2), (4, 5, -1, 4), (6, 7, -1, 6), (8, 9, -1, 8), (1, 2, -1, 1), (3, 4, -1, 3), (5, 6, -1, 5), (7, 8, -1, 7), (0, 9), (1, 10), (2, 11), (3, 12), (4, 13), (5, 14), (6, 15), (7, 16), (8, 17), (9, 18), (0, 1, -1, 19), (2, 3, -1, 21), (4, 5, -1, 23), (6, 7, -1, 25), (8, 9, -1, 27), (1, 2, -1, 20), (3, 4, -1, 22), (5, 6, -1, 24), (7, 8, -1, 26), (0, 28), (1, 29), (2, 30), (3, 31), (4, 32), (5, 33), (6, 34), (7, 35), (8, 36), (9, 37), (0, 1, -1, 38), (2, 3, -1, 40), (4, 5, -1, 42), (6, 7, -1, 44), (8, 9, -1, 46), (1, 2, -1, 39), (3, 4, -1, 41), (5, 6, -1, 43), (7, 8, -1, 45), (0, 47), (1, 48), (2, 49), (3, 50), (4, 51), (5, 52), (6, 53), (7, 54), (8, 55), (9, 56), (0, 1, -1, 57), (2, 3, -1, 59), (4, 5, -1, 61), (6, 7, -1, 63), (8, 9, -1, 65), (1, 2, -1, 58), (3, 4, -1, 60), (5, 6, -1, 62), (7, 8, -1, 64), (0, 66), (1, 67), (2, 68), (3, 69), (4, 70), (5, 71), (6, 72), (7, 73), (8, 74), (9, 75), (0, 1, -1, 76), (2, 3, -1, 78), (4, 5, -1, 80), (6, 7, -1, 82), (8, 9, -1, 84), (1, 2, -1, 77), (3, 4, -1, 79), (5, 6, -1, 81), (7, 8, -1, 83), (0, 85), (1, 86), (2, 87), (3, 88), (4, 89), (5, 90), (6, 91), (7, 92), (8, 93), (9, 94), (0, 1, -1, 95), (2, 3, -1, 97), (4, 5, -1, 99), (6, 7, -1, 101), (8, 9, -1, 103), (1, 2, -1, 96), (3, 4, -1, 98), (5, 6, -1, 100), (7, 8, -1, 102), (0, 104), (1, 105), (2, 106), (3, 107), (4, 108), (5, 109), (6, 110), (7, 111), (8, 112), (9, 113), (0, 1, -1, 114), (2, 3, -1, 116), (4, 5, -1, 118), (6, 7, -1, 120), (8, 9, -1, 122), (1, 2, -1, 115), (3, 4, -1, 117), (5, 6, -1, 119), (7, 8, -1, 121), (0, 123), (1, 124), (2, 125), (3, 126), (4, 127), (5, 128), (6, 129), (7, 130), (8, 131), (9, 132), (0, 1, -1, 133), (2, 3, -1, 135), (4, 5, -1, 137), (6, 7, -1, 139), (8, 9, -1, 141), (1, 2, -1, 134), (3, 4, -1, 136), (5, 6, -1, 138), (7, 8, -1, 140), (0, 142), (1, 143), (2, 144), (3, 145), (4, 146), (5, 147), (6, 148), (7, 149), (8, 150), (9, 151), (0, 1, -1, 152), (2, 3, -1, 154), (4, 5, -1, 156), (6, 7, -1, 158), (8, 9, -1, 160), (1, 2, -1, 153), (3, 4, -1, 155), (5, 6, -1, 157), (7, 8, -1, 159), (0, 161), (1, 162), (2, 163), (3, 164), (4, 165), (5, 166), (6, 167), (7, 168), (8, 169), (9, 170), (0, 1, -1, 171), (2, 3, -1, 173), (4, 5, -1, 175), (6, 7, -1, 177), (8, 9, -1, 179), (1, 2, -1, 172), (3, 4, -1, 174), (5, 6, -1, 176), (7, 8, -1, 178), (0, 180), (1, 181), (2, 182), (3, 183), (4, 184), (5, 185), (6, 186), (7, 187), (8, 188), (9, 189), (0, 1, -1, 190), (2, 3, -1, 192), (4, 5, -1, 194), (6, 7, -1, 196), (8, 9, -1, 198), (1, 2, -1, 191), (3, 4, -1, 193), (5, 6, -1, 195), (7, 8, -1, 197), (0, 199), (1, 200), (2, 201), (3, 202), (4, 203), (5, 204), (6, 205), (7, 206), (8, 207), (9, 208), (0, 1, -1, 209), (2, 3, -1, 211), (4, 5, -1, 213), (6, 7, -1, 215), (8, 9, -1, 217), (1, 2, -1, 210), (3, 4, -1, 212), (5, 6, -1, 214), (7, 8, -1, 216), (0, 218), (1, 219), (2, 220), (3, 221), (4, 222), (5, 223), (6, 224), (7, 225), (8, 226), (9, 227), (0, 1, -1, 228), (2, 3, -1, 230), (4, 5, -1, 232), (6, 7, -1, 234), (8, 9, -1, 236), (1, 2, -1, 229), (3, 4, -1, 231), (5, 6, -1, 233), (7, 8, -1, 235), (0, 237), (1, 238), (2, 239), (3, 240), (4, 241), (5, 242), (6, 243), (7, 244), (8, 245), (9, 246), (0, 1, -1, 247), (2, 3, -1, 249), (4, 5, -1, 251), (6, 7, -1, 253), (8, 9, -1, 255), (1, 2, -1, 248), (3, 4, -1, 250), (5, 6, -1, 252), (7, 8, -1, 254), (0, 256), (1, 257), (2, 258), (3, 259), (4, 260), (5, 261), (6, 262), (7, 263), (8, 264), (9, 265), (0, 1, -1, 266), (2, 3, -1, 268), (4, 5, -1, 270), (6, 7, -1, 272), (8, 9, -1, 274), (1, 2, -1, 267), (3, 4, -1, 269), (5, 6, -1, 271), (7, 8, -1, 273), (0, 275), (1, 276), (2, 277), (3, 278), (4, 279), (5, 280), (6, 281), (7, 282), (8, 283), (9, 284), (0, 1, -1, 285), (2, 3, -1, 287), (4, 5, -1, 289), (6, 7, -1, 291), (8, 9, -1, 293), (1, 2, -1, 286), (3, 4, -1, 288), (5, 6, -1, 290), (7, 8, -1, 292), (0, 294), (1, 295), (2, 296), (3, 297), (4, 298), (5, 299), (6, 300), (7, 301), (8, 302), (9, 303), (0, 1, -1, 304), (2, 3, -1, 306), (4, 5, -1, 308), (6, 7, -1, 310), (8, 9, -1, 312), (1, 2, -1, 305), (3, 4, -1, 307), (5, 6, -1, 309), (7, 8, -1, 311), (0, 313), (1, 314), (2, 315), (3, 316), (4, 317), (5, 318), (6, 319), (7, 320), (8, 321), (9, 322), (0, 1, -1, 323), (2, 3, -1, 325), (4, 5, -1, 327), (6, 7, -1, 329), (8, 9, -1, 331), (1, 2, -1, 324), (3, 4, -1, 326), (5, 6, -1, 328), (7, 8, -1, 330), (0, 332), (1, 333), (2, 334), (3, 335), (4, 336), (5, 337), (6, 338), (7, 339), (8, 340), (9, 341), (0, 1, -1, 342), (2, 3, -1, 344), (4, 5, -1, 346), (6, 7, -1, 348), (8, 9, -1, 350), (1, 2, -1, 343), (3, 4, -1, 345), (5, 6, -1, 347), (7, 8, -1, 349), (0, 351), (1, 352), (2, 353), (3, 354), (4, 355), (5, 356), (6, 357), (7, 358), (8, 359), (9, 360), (0, 1, -1, 361), (2, 3, -1, 363), (4, 5, -1, 365), (6, 7, -1, 367), (8, 9, -1, 369), (1, 2, -1, 362), (3, 4, -1, 364), (5, 6, -1, 366), (7, 8, -1, 368), (0, 370), (1, 371), (2, 372), (3, 373), (4, 374), (5, 375), (6, 376), (7, 377), (8, 378), (9, 379), (0, 1, -1, 380), (2, 3, -1, 382), (4, 5, -1, 384), (6, 7, -1, 386), (8, 9, -1, 388), (1, 2, -1, 381), (3, 4, -1, 383), (5, 6, -1, 385), (7, 8, -1, 387), (0, 389), (1, 390), (2, 391), (3, 392), (4, 393), (5, 394), (6, 395), (7, 396), (8, 397), (9, 398), (0, 1, -1, 399), (2, 3, -1, 401), (4, 5, -1, 403), (6, 7, -1, 405), (8, 9, -1, 407), (1, 2, -1, 400), (3, 4, -1, 402), (5, 6, -1, 404), (7, 8, -1, 406), (0, 408), (1, 409), (2, 410), (3, 411), (4, 412), (5, 413), (6, 414), (7, 415), (8, 416), (9, 417), (0, 1, -1, 418), (2, 3, -1, 420), (4, 5, -1, 422), (6, 7, -1, 424), (8, 9, -1, 426), (1, 2, -1, 419), (3, 4, -1, 421), (5, 6, -1, 423), (7, 8, -1, 425), (0, 427), (1, 428), (2, 429), (3, 430), (4, 431), (5, 432), (6, 433), (7, 434), (8, 435), (9, 436)]\n",
            "\n",
            "Commuting groups per repeat:\n",
            "Group 1: [(0, 1, -1, 418), (2, 3, -1, 420), (4, 5, -1, 422), (6, 7, -1, 424), (8, 9, -1, 426)]\n",
            "Group 2: [(1, 2, -1, 419), (3, 4, -1, 421), (5, 6, -1, 423), (7, 8, -1, 425)]\n"
          ]
        }
      ],
      "source": [
        "# Define parameters\n",
        "para_repeat_times = 23\n",
        "para_value_list = []\n",
        "counting_parameter_index = 0\n",
        "nn_condition = True  # True for nearest-neighbor hopping\n",
        "\n",
        "# Step 1: Generate hopping pairs and U terms for each repeat time\n",
        "for _ in range(para_repeat_times):\n",
        "    hopping_terms = []\n",
        "    U_terms = []\n",
        "\n",
        "    # Generate hopping terms\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            if nn_condition:\n",
        "                if j == i + 1:\n",
        "                    hopping_terms.append((i, j, -1, counting_parameter_index))\n",
        "                    counting_parameter_index += 1\n",
        "            else:\n",
        "                if j > i:\n",
        "                    hopping_terms.append((i, j, -1, counting_parameter_index))\n",
        "                    counting_parameter_index += 1\n",
        "\n",
        "    # Generate U terms\n",
        "    for i in range(N):\n",
        "        U_terms.append((i, counting_parameter_index))\n",
        "        counting_parameter_index += 1\n",
        "\n",
        "    # Step 2: Group commuting terms\n",
        "    def can_commute(term, group):\n",
        "        # A term can commute with a group if none of the sites in the term are present in any terms in the group\n",
        "        term_sites = set(term[:2])  # Extract the two sites involved in the hopping term\n",
        "        for existing_term in group:\n",
        "            existing_sites = set(existing_term[:2])  # Extract sites from existing terms\n",
        "            if term_sites & existing_sites:  # Check if there is any overlap in sites\n",
        "                return False  # Term cannot commute with this group\n",
        "        return True  # Term can commute with this group\n",
        "\n",
        "    # Initialize an empty list to hold groups of commuting terms\n",
        "    commuting_groups = []\n",
        "\n",
        "    # Sort hopping terms into commuting groups\n",
        "    for term in hopping_terms:\n",
        "        added = False\n",
        "        for group in commuting_groups:\n",
        "            if can_commute(term, group):\n",
        "                group.append(term)  # Add term to the group if it commutes with all terms in the group\n",
        "                added = True\n",
        "                break\n",
        "        if not added:\n",
        "            commuting_groups.append([term])  # Start a new group if it doesn't commute with any existing group\n",
        "\n",
        "    # Step 3: Flatten the list of groups into the final ordered list (only for hopping terms)\n",
        "    ordered_hopping_list = [term for group in commuting_groups for term in group]\n",
        "\n",
        "    # Step 4: Append the hopping terms and U terms in the correct order\n",
        "    para_value_list.extend(ordered_hopping_list)\n",
        "    para_value_list.extend(U_terms)\n",
        "\n",
        "# Return the final list\n",
        "print(\"Final para_value_list with commuting groups and U terms ordered:\")\n",
        "print(len(para_value_list), para_value_list)\n",
        "\n",
        "# Optional: You can also print the groups if you'd like to visualize them\n",
        "print(\"\\nCommuting groups per repeat:\")\n",
        "for idx, group in enumerate(commuting_groups):\n",
        "    print(f\"Group {idx+1}: {group}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8dE7yQalomw"
      },
      "outputs": [],
      "source": [
        "# # also save the ops list\n",
        "# file_path = f'/content/drive/My Drive/Hubbard_2024/2d/result/para_list_N={N}_U={U_value}_steps_{para_repeat_times}.txt'\n",
        "# with open(file_path, 'w') as f:\n",
        "#     for item in para_value_list:\n",
        "#         f.write(f\"{item}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCVjZavTO1rJ"
      },
      "outputs": [],
      "source": [
        "# evolve state\n",
        "# also get fidelity during the time evolution\n",
        "def evolve_state(x):\n",
        "    fidelity_list = []\n",
        "    energy_list = []\n",
        "    state_to_evolve_1 = state_to_evolve.clone()\n",
        "\n",
        "    for para_index in para_value_list:\n",
        "        if len(para_index) == 2:  # This is non-hopping only\n",
        "            new_state = UCC_U_part_torch(state_to_evolve_1, para_index[0], x[para_index[1]])\n",
        "        else:\n",
        "            site_index = para_index[:2]\n",
        "            rl_sign = para_index[2]\n",
        "            x_index = para_index[3]\n",
        "            new_state = UCC_t_part_torch(state_to_evolve_1, site_index, rl_sign, x[x_index])\n",
        "\n",
        "        # Update state for next loop\n",
        "        state_to_evolve_1 = new_state\n",
        "        #fidelity_list.append(calculate_fidelity( true_gs,state_to_evolve_1))\n",
        "        #energy_list.append(calculate_energy(h_sparse,state_to_evolve_1))\n",
        "    return state_to_evolve_1\n",
        "\n",
        "\n",
        "def classical_optimizer(x):\n",
        "    \"\"\"\n",
        "    Perform classical optimization.\n",
        "    Parameters:\n",
        "    x (torch.Tensor): The parameter tensor.\n",
        "    state_to_evolve (torch.Tensor): The initial state tensor.\n",
        "    para_value_list (list): The list of parameter indices.\n",
        "    h_sparse (torch.sparse.FloatTensor or torch.sparse.DoubleTensor): The sparse Hamiltonian matrix.\n",
        "\n",
        "    Returns:\n",
        "    float64: The calculated energy.\n",
        "    \"\"\"\n",
        "    state_to_evolve_1 = state_to_evolve.clone()\n",
        "\n",
        "    for para_index in para_value_list:\n",
        "        if len(para_index) == 2:  # This is non-hopping only\n",
        "            new_state = UCC_U_part_torch(state_to_evolve_1, para_index[0], x[para_index[1]])\n",
        "        else:\n",
        "            site_index = para_index[:2]\n",
        "            rl_sign = para_index[2]\n",
        "            x_index = para_index[3]\n",
        "            new_state = UCC_t_part_torch(state_to_evolve_1, site_index, rl_sign, x[x_index])\n",
        "\n",
        "        # Update state for next loop\n",
        "        state_to_evolve_1 = new_state\n",
        "\n",
        "    new_energy = calculate_energy(h_sparse, new_state)\n",
        "    #print(calculate_fidelity( true_gs,new_state))\n",
        "    return new_energy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1s_HZFYE5Cw"
      },
      "outputs": [],
      "source": [
        " # read\n",
        "# file_path = f'/content/drive/My Drive/Hubbard_2024/final_data/8_sites/para_list_N={N}_U={U_value}_steps_{para_repeat_times}.txt'\n",
        "# para_value_list = []\n",
        "\n",
        "# # Open the file and read the data\n",
        "# with open(file_path, 'r') as f:\n",
        "#     for line in f:\n",
        "#         # Safely evaluate the line to convert it from string to tuple/list\n",
        "#         item = ast.literal_eval(line.strip())\n",
        "#         para_value_list.append(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1x3itb-d2ubX"
      },
      "outputs": [],
      "source": [
        "# x = torch.tensor(np.random.uniform(-0.01, 0.01, counting_parameter_index), dtype=torch.float64, device=device, requires_grad=True)\n",
        "# classical_optimizer(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOCNy8ggQ1xf"
      },
      "outputs": [],
      "source": [
        "# from typing_extensions import final\n",
        "# import torch\n",
        "# import torch.optim as optim\n",
        "# import os\n",
        "# import numpy as np\n",
        "\n",
        "# lr = 0.1\n",
        "# gradient_threshold = 0.001\n",
        "# filename = f'/content/drive/My Drive/Hubbard_2024/2d/result/LBFGS_log_hubbard_{N}_sites_U_{U_value}_steps_{para_repeat_times}.txt'\n",
        "# checkpoint_filename = f'/content/drive/My Drive/Hubbard_2024/2d/result/LBFGS_checkpoint_hubbard_{N}_sites_U_{U_value}_steps_{para_repeat_times}.pt'\n",
        "# max_epochs = 50000\n",
        "\n",
        "\n",
        "# # CPU version\n",
        "# if os.path.isfile(checkpoint_filename):\n",
        "#     # Load checkpoint with appropriate map_location\n",
        "#     checkpoint = torch.load(checkpoint_filename, map_location=device)\n",
        "#     x = torch.tensor(checkpoint['x'], dtype=torch.float64, device=device, requires_grad=True)\n",
        "\n",
        "#     # Initialize L-BFGS optimizer\n",
        "#     optimizer = optim.LBFGS([x], lr=lr)\n",
        "#     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#     epoch = checkpoint['epoch']\n",
        "# else:\n",
        "#     x = torch.tensor(np.random.uniform(-0.01, 0.01, counting_parameter_index), dtype=torch.float64, device=device, requires_grad=True)\n",
        "#     optimizer = optim.LBFGS([x], lr=lr, max_iter=20, history_size=100)\n",
        "#     epoch = 0\n",
        "\n",
        "# def closure():\n",
        "#     optimizer.zero_grad()\n",
        "#     energy = classical_optimizer(x)\n",
        "#     energy.backward()\n",
        "#     return energy\n",
        "\n",
        "# with open(filename, 'a') as f:  # Use 'a' to append to the log file if it exists\n",
        "#     while epoch < max_epochs:\n",
        "#         optimizer.step(closure)\n",
        "\n",
        "#         # Log and save data\n",
        "#         gradient_norm = x.grad.norm().cpu().detach().numpy()\n",
        "#         if (epoch + 1) % 1 == 0:\n",
        "#             result_str = f\"Epoch {epoch + 1}, Energy: {classical_optimizer(x).cpu().detach().numpy():.6f}, Gradient Norm: {gradient_norm:.6f}\\n\"\n",
        "#             f.write(result_str)\n",
        "#             print(result_str, end='')\n",
        "\n",
        "#             # Append latest x values to the end of the file\n",
        "#             x_values = ','.join([str(val.item()) for val in x.detach().cpu().numpy()])\n",
        "#             f.write(f\"Latest x values at epoch {epoch + 1}: {x_values}\\n\")\n",
        "\n",
        "#             # Save checkpoint\n",
        "#             torch.save({\n",
        "#                 'epoch': epoch,\n",
        "#                 'x': x.detach().cpu().numpy(),  # Save as numpy array for checkpoint\n",
        "#                 'optimizer_state_dict': optimizer.state_dict(),\n",
        "#             }, checkpoint_filename)\n",
        "\n",
        "#         # Increment epoch counter\n",
        "#         epoch += 1\n",
        "#         f.flush()\n",
        "\n",
        "#         # check if gradient is smaller than threshold\n",
        "#         if gradient_norm < gradient_threshold:\n",
        "#             break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwYcTRQ2-ZFE"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import final\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "lr = 0.1\n",
        "gradient_threshold = 0.001\n",
        "filename = f'/content/drive/My Drive/Hubbard_2024/2d/result/LBFGS_log_hubbard_{N}_sites_U_{U_value}_steps_{para_repeat_times}.txt'\n",
        "checkpoint_filename = f'/content/drive/My Drive/Hubbard_2024/2d/result/LBFGS_checkpoint_hubbard_{N}_sites_U_{U_value}_steps_{para_repeat_times}.pt'\n",
        "max_epochs = 50000\n",
        "\n",
        "# GPU version\n",
        "\n",
        "# Initialize x if checkpoint does not exist\n",
        "if os.path.isfile(checkpoint_filename):\n",
        "    checkpoint = torch.load(checkpoint_filename)\n",
        "    x = torch.tensor(checkpoint['x'], dtype=torch.float64, device=device, requires_grad=True)\n",
        "\n",
        "    # Initialize L-BFGS optimizer\n",
        "    optimizer = optim.LBFGS([x], lr=lr)\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "else:\n",
        "    x = torch.tensor(np.random.uniform(-0.001, 0.001, counting_parameter_index), dtype=torch.float64, device=device, requires_grad=True)\n",
        "    optimizer = optim.LBFGS([x], lr=lr, max_iter=20, history_size=1000)\n",
        "    epoch = 0\n",
        "\n",
        "def closure():\n",
        "    optimizer.zero_grad()\n",
        "    energy = classical_optimizer(x)\n",
        "    energy.backward()\n",
        "    return energy\n",
        "\n",
        "with open(filename, 'a') as f:  # Use 'a' to append to the log file if it exists\n",
        "    while epoch < max_epochs:\n",
        "        optimizer.step(closure)\n",
        "\n",
        "        # Log and save data\n",
        "        gradient_norm = x.grad.norm().cpu().detach().numpy()\n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            result_str = f\"Epoch {epoch + 1}, Energy: {classical_optimizer(x).cpu().detach().numpy():.6f}, Gradient Norm: {gradient_norm:.6f}\\n\"\n",
        "            f.write(result_str)\n",
        "            print(result_str, end='')\n",
        "\n",
        "            # Append latest x values to the end of the file\n",
        "            x_values = ','.join([str(val.item()) for val in x.detach().cpu().numpy()])\n",
        "            f.write(f\"Latest x values at epoch {epoch + 1}: {x_values}\\n\")\n",
        "\n",
        "            # Save checkpoint\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'x': x.detach().cpu().numpy(),  # Save as numpy array for checkpoint\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "            }, checkpoint_filename)\n",
        "\n",
        "        # L-BFGS does not use gradient threshold for stopping; you may need a custom stopping condition\n",
        "        epoch += 1\n",
        "        f.flush()\n",
        "\n",
        "        # check if gradient is smaller than threshold\n",
        "        if gradient_norm < gradient_threshold:\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUuKha8f286c"
      },
      "outputs": [],
      "source": [
        "filename = f'/content/drive/My Drive/Hubbard_2024/2d/result/final_report_{N}_sites_U_{U_value}_steps_{para_repeat_times}.txt'\n",
        "\n",
        "# once done write result file\n",
        "\n",
        "#outcome result\n",
        "length = len(para_value_list)\n",
        "\n",
        "# Determine if tensor 'x' is on GPU or CPU\n",
        "if x.is_cuda:\n",
        "    # GPU version\n",
        "    final_energy_ratio = classical_optimizer(x).detach().cpu().numpy() / true_gs_energy\n",
        "else:\n",
        "    # CPU version\n",
        "    final_energy_ratio = classical_optimizer(x).detach().numpy() / true_gs_energy\n",
        "\n",
        "######################################################################\n",
        "\n",
        "final_fidelity = calculate_fidelity( true_gs,evolve_state(x))\n",
        "x_values = ','.join([str(val.item()) for val in x.detach().cpu().numpy()])\n",
        "# Write results to file\n",
        "with open(filename, 'w') as file:\n",
        "    file.write(f\"Final Energy Ratio: {final_energy_ratio}\\n\")\n",
        "    file.write(f\"Final Fidelity: {final_fidelity}\\n\")\n",
        "    file.write(f\"Optimized X Values: {x_values}\\n\")\n",
        "    file.write(f\"Length of parameter value list: {length}\\n\")\n",
        "    file.write(f\"Epoch : {epoch }\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w16HVQ9u9LA4"
      },
      "outputs": [],
      "source": [
        "# Read the results from the file\n",
        "with open(filename, 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Print the file content\n",
        "print(content)\n",
        "\n",
        "import re\n",
        "import torch\n",
        "\n",
        "# Assuming 'content' is a string variable containing the text and 'device' is defined\n",
        "x_values_match = re.search(r\"Optimized X Values: (.*)\", content)\n",
        "if x_values_match:\n",
        "  x_values_str = x_values_match.group(1)\n",
        "  x_values = [float(x) for x in x_values_str.split(',')]\n",
        "  x = torch.tensor(x_values, dtype=torch.float64, device=device, requires_grad=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfXn5Ig0PZUz"
      },
      "outputs": [],
      "source": [
        "# filename = f'/content/drive/My Drive/Hubbard_2024/2d/final_result/final_report_{N}_sites_U_{U_value}_steps_{para_repeat_times}.txt'\n",
        "\n",
        "# # Read the results from the file\n",
        "# with open(filename, 'r') as file:\n",
        "#     content = file.read()\n",
        "\n",
        "# # Print the file content\n",
        "# print(content)\n",
        "\n",
        "# import re\n",
        "# import torch\n",
        "\n",
        "# # Assuming 'content' is a string variable containing the text and 'device' is defined\n",
        "# x_values_match = re.search(r\"Optimized X Values: (.*)\", content)\n",
        "# if x_values_match:\n",
        "#   x_values_str = x_values_match.group(1)\n",
        "#   x_values = [float(x) for x in x_values_str.split(',')]\n",
        "#   x = torch.tensor(x_values, dtype=torch.float64, device=device, requires_grad=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egZ5RjE3PiJi"
      },
      "outputs": [],
      "source": [
        "# f_list,e_list= evolve_state(x)\n",
        "# plt.plot(f_list)\n",
        "# plt.xlabel('Index of parameter m', fontsize=18)\n",
        "# plt.ylabel('ground state\\nfidelity', fontsize=18)  # Split the ylabel into two lines using \\n\n",
        "# plt.xticks([0,200,400,600,800],fontsize=18)  # Set x-tick label size\n",
        "# plt.yticks(fontsize=18)  # Set y-tick label size\n",
        "# plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
